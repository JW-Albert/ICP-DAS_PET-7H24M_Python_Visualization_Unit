# PET-7H24M 即時資料可視化系統 - 詳細程式運作說明

## 目錄

1. [專案概述](#專案概述)
2. [系統架構](#系統架構)
3. [核心模組詳細說明](#核心模組詳細說明)
4. [資料流程](#資料流程)
5. [Web 介面與 API](#web-介面與-api)
6. [執行緒架構](#執行緒架構)
7. [設定檔說明](#設定檔說明)
8. [檔案結構](#檔案結構)
9. [程式碼詳細解析](#程式碼詳細解析)
10. [運作流程](#運作流程)

---

## 專案概述

### 平台資訊

**目標平台**：LinuxArm64 (aarch64)

本系統針對 ARM64 架構的 Linux 系統進行開發與優化，需要 ARM64 版本的 HSDAQ 函式庫（libhsdaq.so）。

### 系統目的

PET-7H24M 即時資料可視化系統是一個基於 Python 的振動數據採集與可視化平台，主要功能包括：

1. **從 PET-7H24M 設備採集振動數據**：透過 TCP/IP 協議（使用 HSDAQ 函式庫）從硬體設備讀取多通道振動數據
2. **即時資料可視化**：在瀏覽器中即時顯示連續振動曲線圖
3. **自動 CSV 儲存**：根據設定的時間間隔自動分檔儲存資料
4. **SQL 資料庫上傳**：可選的 MySQL/MariaDB 上傳功能
5. **Web 介面控制**：提供完整的瀏覽器操作介面，無需終端機操作

### 技術棧

- **平台**：LinuxArm64 (aarch64)
- **後端**：Python 3.9+
- **Web 框架**：Flask 3.1.2+
- **通訊協議**：TCP/IP（透過 HSDAQ 函式庫）
- **前端可視化**：Chart.js 3.9.1
- **資料儲存**：CSV 格式、MySQL/MariaDB（可選）
- **函式庫**：libhsdaq.so（ICP-DAS 官方函式庫，ARM64 版本）

---

## 系統架構

### 整體架構圖

```
┌─────────────────────────────────────────────────────────────┐
│                      Web 瀏覽器（前端）                       │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  index.html: 即時圖表、控制按鈕、狀態顯示              │  │
│  │  config.html: 設定檔編輯介面                          │  │
│  │  files.html: 檔案瀏覽介面                             │  │
│  └───────────────────────────────────────────────────────┘  │
└───────────────────────┬─────────────────────────────────────┘
                        │ HTTP/JSON
                        ▼
┌─────────────────────────────────────────────────────────────┐
│                 Flask Web 伺服器 (main.py)                   │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  Flask Thread: 處理 HTTP 請求                          │  │
│  │  - /: 主頁                                             │  │
│  │  - /data: 回傳即時資料                                 │  │
│  │  - /start: 啟動資料收集                                │  │
│  │  - /stop: 停止資料收集                                 │  │
│  │  - /config: 設定檔管理                                 │  │
│  │  - /files: 檔案瀏覽                                    │  │
│  └───────────────────────────────────────────────────────┘  │
└───────────────────────┬─────────────────────────────────────┘
                        │
        ┌───────────────┼───────────────┐
        │               │               │
        ▼               ▼               ▼
┌───────────────┐ ┌───────────────┐ ┌───────────────┐
│  Collection   │ │  CSV Writer   │ │  SQL Writer   │
│  Thread       │ │  Thread       │ │  Thread       │
│  (資料收集迴圈)│ │  (檔案寫入)   │ │  (資料庫上傳) │
└───────┬───────┘ └───────────────┘ └───────────────┘
        │
        ▼
┌─────────────────────────────────────────────────────────────┐
│              PET7H24M 類別 (pet7h24m.py)                      │
│  ┌───────────────────────────────────────────────────────┐  │
│  │  Reading Thread: TCP/IP 讀取迴圈                      │  │
│  │  - 使用 HSDAQ 函式庫讀取設備資料                      │  │
│  │  - 資料轉換（浮點數）                                  │  │
│  │  - 放入資料佇列 (queue.Queue)                        │  │
│  └───────────────────────────────────────────────────────┘  │
└───────────────────────┬─────────────────────────────────────┘
                        │ TCP/IP (HSDAQ)
                        ▼
┌─────────────────────────────────────────────────────────────┐
│              PET-7H24M 硬體設備                              │
│  - IP 位址：192.168.255.1（可配置）                          │
│  - 取樣率：20000 Hz（可配置）                               │
│  - 通道數：最多 4 通道（AI0-AI3，可選）                      │
└─────────────────────────────────────────────────────────────┘
```

### 模組關係

1. **main.py**（主控制程式）
   - 整合所有模組
   - 提供 Flask Web 服務
   - 管理執行緒和全域狀態

2. **pet7h24m.py**（硬體通訊模組）
   - 處理 TCP/IP 通訊（透過 HSDAQ 函式庫）
   - 讀取設備資料
   - 資料轉換與佇列管理

3. **csv_writer.py**（資料儲存模組）
   - CSV 檔案建立與寫入
   - 自動分檔邏輯

4. **sql_uploader.py**（資料庫上傳模組）
   - MySQL/MariaDB 連線管理
   - 資料批次上傳
   - 暫存檔案管理

5. **templates/**（前端介面）
   - HTML 模板與 JavaScript
   - Chart.js 圖表顯示

---

## 核心模組詳細說明

### 1. pet7h24m.py - PET7H24M 類別

#### 類別結構

```python
class PET7H24M:
    - device_handle: c_void_p           # HSDAQ 設備控制代碼
    - device_ip: str                     # 設備 IP 位址
    - device_port: int                   # 設備埠號
    - sample_rate: int                   # 取樣率 (Hz)
    - channel_mask: int                  # 通道遮罩（位元遮罩）
    - active_channels: List[int]          # 啟用的通道列表
    - channels_count: int                # 啟用的通道數
    - reading: bool                       # 讀取狀態旗標
    - reading_thread: Thread              # 讀取執行緒
    - data_queue: queue.Queue            # 資料佇列（最大 1000 筆）
```

#### 主要方法

##### `init_devices(ini_path: str)`

**功能**：從 INI 設定檔初始化設備並建立 TCP/IP 連線

**運作流程**：
1. 讀取 `PET-7H24M.ini` 設定檔
   - `device_ip`: 設備 IP 位址（預設 `192.168.255.1`）
   - `device_port`: 設備埠號（預設 `502`）
   - `sample_rate`: 取樣率（預設 `20000` Hz）
   - `enable_ai0` ~ `enable_ai3`: 各通道啟用狀態（預設全部啟用）

2. 計算通道遮罩
   - AI0=1, AI1=2, AI2=4, AI3=8
   - 根據啟用狀態計算位元遮罩

3. 建立 TCP/IP 連線
   - 使用 `HS_Device_Create()` 建立設備連線
   - 設定類比輸入掃描參數（`HS_SetAIScanParam`）

4. 驗證參數設定
   - 使用 `HS_GetAIScanParam()` 驗證參數是否正確設定

**錯誤處理**：
- 連線失敗時輸出錯誤訊息並拋出例外
- INI 檔案解析錯誤時使用預設值

##### `start_reading()`

**功能**：啟動背景執行緒開始讀取資料

**運作流程**：
1. 檢查是否已在讀取中（避免重複啟動）
2. 啟動類比輸入掃描（`HS_StartAIScan`）
3. 設定 `reading = True`
4. 建立並啟動背景執行緒執行 `_read_loop()`
5. 執行緒設定為 `daemon=True`（主程式結束時自動終止）

##### `_read_loop()`

**功能**：主要的資料讀取迴圈（在獨立執行緒中執行）

**運作流程**：

1. **取得緩衝區狀態**
   - 使用 `HS_GetAIBufferStatus()` 取得緩衝區狀態和資料數量
   - 檢查緩衝區錯誤（溢位、停止、其他錯誤）

2. **決定讀取模式**
   - **AI Buffer Continue 模式**（`target_count = 0`）：有資料就讀取
   - **N Sample 模式**（`target_count > 0`）：等待達到目標數量後讀取

3. **讀取資料**
   - 使用 `HS_GetAIBuffer()` 讀取緩衝區資料
   - 確保讀取數量是通道數的倍數
   - 轉換為 Python 浮點數列表

4. **放入佇列**
   - 使用 `queue.put_nowait(data)` 放入佇列
   - 如果佇列已滿，移除最舊的資料（FIFO）

5. **錯誤處理**
   - 連續錯誤超過 5 次時停止讀取
   - 緩衝區溢位時停止掃描

**設計理由**：
- 支援兩種讀取模式，適應不同應用場景
- 使用佇列緩衝，避免資料遺失
- 自動錯誤處理，確保系統穩定性

##### `get_data() -> List[float]`

**功能**：非阻塞式取得資料（從佇列取出）

**運作方式**：
- 使用 `queue.get_nowait()` 非阻塞取得資料
- 如果佇列為空，返回空陣列 `[]`
- 避免阻塞主執行緒

##### `stop_reading()`

**功能**：停止讀取並清理資源

**運作流程**：
1. 設定 `reading = False`（停止讀取迴圈）
2. 停止類比輸入掃描（`HS_StopAIScan`）
3. 等待讀取執行緒結束（`join()`）
4. 清空資料佇列
5. 釋放設備連線（`HS_Device_Release`）

---

### 2. csv_writer.py - CSVWriter 類別

#### 類別結構

```python
class CSVWriter:
    - channels: int                    # 通道數量（動態）
    - output_dir: str                   # 輸出目錄路徑
    - label: str                        # 資料標籤
    - sample_rate: int                  # 取樣率
    - file_counter: int                 # 檔案計數器
    - current_file: file                # 當前開啟的檔案物件
    - writer: csv.writer                # CSV 寫入器物件
```

#### 主要方法

##### `__init__(channels, output_dir, label, sample_rate)`

**功能**：初始化 CSV 寫入器

**運作流程**：
1. 儲存參數（通道數、輸出目錄、標籤、取樣率）
2. 初始化檔案計數器為 1
3. 建立輸出目錄（如果不存在）
4. 建立第一個 CSV 檔案

##### `_create_new_file()`

**功能**：建立新的 CSV 檔案

**運作流程**：
1. 產生檔案名稱：`{timestamp}_{label}_{file_counter:03d}.csv`
   - 時間戳記格式：`YYYYMMDDHHMMSS`
   - 檔案計數器：3 位數，從 001 開始
2. 開啟檔案（UTF-8 編碼）
3. 建立 CSV 寫入器
4. 寫入標題行：`['Timestamp'] + [f'Channel_{i+1}' for i in range(channels)]`
5. 立即寫入磁碟（`flush()`）

##### `add_data_block(data: List[float])`

**功能**：將資料區塊寫入 CSV 檔案

**運作流程**：
1. 檢查資料是否為空
2. 取得當前時間戳記（ISO 格式）
3. **按通道分組寫入**：
   - 資料格式：`[ch1_val, ch2_val, ch1_val, ch2_val, ...]`（交錯格式）
   - 每 N 個資料點為一組（對應 N 個通道）
   - 寫入格式：`[timestamp, channel_1_value, channel_2_value, ...]`
4. 如果資料不足通道數的倍數，不足的通道填充 0.0
5. 立即寫入磁碟（`flush()`）

##### `update_filename()`

**功能**：建立新檔案（分檔）

**運作流程**：
1. 關閉當前檔案
2. 檔案計數器遞增
3. 呼叫 `_create_new_file()` 建立新檔案

##### `close()`

**功能**：關閉 CSV 檔案

**運作流程**：
1. 關閉檔案物件
2. 清空檔案和寫入器參考

---

### 3. main.py - Flask Web 伺服器與主控制程式

#### 全域狀態變數

```python
app: Flask                              # Flask 應用程式實例
web_data_queue: queue.Queue             # Web 顯示專用佇列（降頻後的資料）
WEB_DOWNSAMPLE_RATIO: int = 25          # 降頻比例（每 25 點取 1 點）
csv_data_queue: queue.Queue             # CSV 資料佇列（原始資料）
sql_data_queue: queue.Queue             # SQL 資料佇列（原始資料）
data_lock: threading.Lock               # 資料存取鎖定
is_collecting: bool                     # 資料收集狀態旗標
collection_thread: Thread               # 資料收集執行緒
csv_writer_thread: Thread               # CSV 寫入執行緒
sql_writer_thread: Thread               # SQL 寫入執行緒
daq_instance: PET7H24M                  # DAQ 實例
csv_writer_instance: CSVWriter          # CSV 寫入器實例
sql_uploader_instance: SQLUploader      # SQL 上傳器實例
data_counter: int                       # 資料點計數器
target_size: int                        # 每個 CSV 檔案的目標資料點數
current_data_size: int                  # 當前檔案已寫入的資料點數
sql_target_size: int                     # 每個 SQL 上傳批次的目標資料點數
sql_current_data_size: int              # 當前批次已累積的資料點數
channels: int                           # 通道數（動態取得）
```

#### 核心函數

##### `update_realtime_data(data: List[float])`

**功能**：更新即時資料（針對 Web 顯示進行降頻處理）

**核心架構**：
- 降頻佇列：`web_data_queue`（最大 50,000 筆）
- 降頻比例：25（每 25 點取 1 點）
- 原始採樣率：20000 Hz → 降頻後約 800 Hz
- 前端資料傳輸量減少約 96%

**運作流程**：

1. **防止佇列溢位**
   - 如果 `web_data_queue` 已滿，丟棄 10 筆舊資料
   - 保護記憶體，避免前端卡死時導致記憶體溢出

2. **降頻處理（Downsampling）**
   - 資料格式：`[ch1, ch2, ch1, ch2, ...]`（交錯格式）
   - 計算步長：`step = channels * WEB_DOWNSAMPLE_RATIO`
   - 使用步進切片：`for i in range(0, len(data), step)`
   - 確保每次取出的都是完整的通道組
   - 擷取資料片段並放入降頻後的陣列

3. **放入 Web 佇列**
   - 如果降頻後的資料不為空，放入 `web_data_queue`
   - 使用 `data_lock` 確保執行緒安全

4. **更新計數器**
   - 更新 `data_counter`（總資料點數，用於狀態顯示）

**設計理由**：
- 降頻處理：大幅減少前端資料傳輸量和繪圖負擔
- 佇列機制：使用佇列而非大型緩衝區，記憶體使用更穩定
- 原始資料保留：CSV 和 SQL 仍使用原始資料（不降頻），確保資料完整性

##### `collection_loop()`

**功能**：資料收集主迴圈（在獨立執行緒中執行）

**運作流程**：
1. 從 DAQ 取得資料（`daq_instance.get_data()`）
2. 更新即時資料（`update_realtime_data()`）
3. 將資料放入 CSV 佇列（`csv_data_queue`）
4. 如果啟用 SQL，將資料放入 SQL 佇列（`sql_data_queue`）
5. 持續迴圈直到 `is_collecting = False`

##### `csv_writer_loop()`

**功能**：CSV 寫入迴圈（在獨立執行緒中執行）

**運作流程**：
1. 從 `csv_data_queue` 取得資料
2. 累積資料點數（`current_data_size`）
3. 如果未達到目標大小（`target_size`），直接寫入
4. 如果達到目標大小，分檔處理：
   - 寫入當前檔案的剩餘空間
   - 建立新檔案（`update_filename()`）
   - 將剩餘資料寫入新檔案
5. 持續迴圈直到 `is_collecting = False` 且佇列為空

##### `sql_writer_loop()`

**功能**：SQL 寫入迴圈（在獨立執行緒中執行）

**運作流程**：
1. 從 `sql_data_queue` 取得資料
2. 將資料寫入暫存 CSV 檔案
3. 累積資料點數（`sql_current_data_size`）
4. 如果達到目標大小（`sql_target_size`），上傳檔案並建立新暫存檔案
5. 持續迴圈直到 `is_collecting = False` 且佇列為空

---

## 資料流程

### 完整資料流程圖

```
PET-7H24M 設備
    ↓ (TCP/IP, HSDAQ 函式庫)
PET7H24M 類別 (pet7h24m.py)
    ├─ Reading Thread: 讀取資料
    └─ data_queue: 資料佇列
        ↓
主程式 (main.py)
    ├─ Collection Thread: 資料處理與分發
    │   ├─→ update_realtime_data(): 降頻處理
    │   │   └─→ web_data_queue: 降頻後的資料
    │   │       ↓
    │   │   Flask /data API
    │   │       ↓
    │   │   前端 Chart.js (templates/index.html)
    │   │
    │   ├─→ csv_data_queue: 原始資料
    │   │       ↓
    │   │   CSV Writer Thread
    │   │       ↓
    │   │   CSVWriter 類別 (csv_writer.py)
    │   │       ↓
    │   │   CSV 檔案
    │   │
    │   └─→ sql_data_queue: 原始資料（如果啟用）
    │           ↓
    │       SQL Writer Thread
    │           ↓
    │       SQLUploader 類別 (sql_uploader.py)
    │           ↓
    │       暫存 CSV 檔案
    │           ↓
    │       MySQL/MariaDB 資料庫
```

### 資料格式

#### 原始資料格式（從設備讀取）

```
[ch1_val, ch2_val, ch1_val, ch2_val, ...]
```

- 交錯格式：通道資料交替排列
- 浮點數：已由 HSDAQ 函式庫轉換為浮點數

#### 降頻後資料格式（Web 顯示）

```
[ch1_val, ch2_val, ch1_val, ch2_val, ...]  # 每 25 點取 1 點
```

#### CSV 檔案格式

```csv
Timestamp,Channel_1,Channel_2
2025-01-06T12:00:00.123456,0.123,0.456
2025-01-06T12:00:00.123500,0.234,0.567
```

#### SQL 資料表格式

```sql
CREATE TABLE `20250106120000_test_001` (
    `Timestamp` DATETIME(6) NOT NULL,
    `Channel_1` FLOAT,
    `Channel_2` FLOAT,
    PRIMARY KEY (`Timestamp`)
);
```

---

## Web 介面與 API

### API 路由說明

| 路由 | 方法 | 功能說明 |
|------|------|----------|
| `/` | GET | 主頁，顯示設定表單、Label 輸入、開始/停止按鈕與折線圖 |
| `/data` | GET | 回傳目前最新資料 JSON 給前端（降頻後的資料） |
| `/status` | GET | 檢查資料收集狀態（用於前端狀態恢復） |
| `/config` | GET | 顯示設定檔編輯頁面 |
| `/config` | POST | 儲存修改後的設定檔 |
| `/sql_config` | GET | 取得 SQL 設定（從 sql.ini 讀取） |
| `/start` | POST | 啟動 DAQ、CSVWriter、SQLUploader 與即時顯示 |
| `/stop` | POST | 停止所有執行緒、安全關閉 |
| `/files_page` | GET | 檔案瀏覽頁面 |
| `/files` | GET | 列出 output 目錄中的檔案和資料夾（查詢參數：path） |
| `/download` | GET | 下載檔案（查詢參數：path） |

### API 回應格式

#### `/data` 回應

```json
{
    "success": true,
    "data": [0.123, 0.456, 0.234, 0.567, ...],
    "counter": 123456,
    "sample_rate": 20000,
    "is_collecting": true,
    "start_time": "2025-01-06T12:00:00"
}
```

#### `/start` 請求

```json
{
    "label": "test_001",
    "sql_enabled": false,
    "sql_host": "localhost",
    "sql_port": "3306",
    "sql_user": "root",
    "sql_password": "password",
    "sql_database": "pet7h24m"
}
```

#### `/start` 回應

```json
{
    "success": true,
    "message": "資料收集已啟動 (取樣率: 20000 Hz, 通道數: 2, 分檔間隔: 60 秒, SQL 上傳間隔: 60 秒)"
}
```

---

## 執行緒架構

### 執行緒列表

| 執行緒 | 功能 | 類型 | 狀態管理 |
|--------|------|------|----------|
| **主執行緒** | 控制流程、等待中斷 | 主執行緒 | - |
| **Flask Thread** | 處理 HTTP 請求 | daemon=True | 主程式結束時自動終止 |
| **Reading Thread** (PET7H24M) | TCP/IP 資料讀取迴圈 | daemon=True | `reading` 旗標 |
| **Collection Thread** (main.py) | 資料處理與分發 | daemon=True | `is_collecting` 旗標 |
| **CSV Writer Thread** (main.py) | CSV 檔案寫入 | daemon=True | `is_collecting` 旗標 |
| **SQL Writer Thread** (main.py) | SQL 資料上傳 | daemon=True | `is_collecting` 旗標 |

### 執行緒通訊

- **資料佇列**：使用 `queue.Queue` 進行執行緒間通訊
  - `data_queue`（PET7H24M → Collection）
  - `web_data_queue`（Collection → Flask）
  - `csv_data_queue`（Collection → CSV Writer）
  - `sql_data_queue`（Collection → SQL Writer）

- **執行緒鎖**：使用 `threading.Lock` 保護共享資源
  - `data_lock`：保護 `web_data_queue` 的存取

---

## 設定檔說明

### PET-7H24M.ini

```ini
[PET7H24M]
device_ip = 192.168.255.1      # 設備 IP 位址
device_port = 502              # 設備埠號
sample_rate = 20000            # 取樣率（Hz）
enable_ai0 = 1                 # 啟用 AI0 通道（1=啟用, 0=停用）
enable_ai1 = 1                 # 啟用 AI1 通道
enable_ai2 = 0                 # 啟用 AI2 通道
enable_ai3 = 0                 # 啟用 AI3 通道
gain = 0                       # 增益
trigger_mode = 0               # 觸發模式
target_count = 0               # 目標計數（0=連續採集）
data_trans_method = 0          # 資料傳輸方式
auto_run = 0                   # 自動執行模式
```

### csv.ini

```ini
[CSVServer]
enabled = false                # CSV 功能是否啟用（目前未使用）

[DumpUnit]
second = 60                    # 每個 CSV 檔案的資料時間長度（秒）
```

**分檔邏輯說明**：
- 系統會根據 `sample_rate × channels × second` 計算每個檔案應包含的資料點數
- 當累積的資料點數達到目標值時，自動建立新檔案
- 例如：取樣率 20000 Hz，2 通道，60 秒 → 每個檔案約 2,400,000 個資料點

### sql.ini

```ini
[SQLServer]
enabled = false               # SQL 功能是否啟用
host = localhost              # 資料庫主機位址
port = 3306                   # 資料庫埠號
user = root                   # 資料庫使用者名稱
password =                     # 資料庫密碼
database = pet7h24m           # 資料庫名稱

[DumpUnit]
second = 60                   # 每個 SQL 上傳批次的資料時間長度（秒）
```

**上傳邏輯說明**：
- 系統會根據 `sample_rate × channels × second` 計算每個批次應包含的資料點數
- 當累積的資料點數達到目標值時，自動上傳暫存檔案到資料庫
- 上傳成功後刪除暫存檔案，建立新的暫存檔案

---

## 檔案結構

```
ICP-DAS_PET-7H24M_Python_Visualization_Unit/
│
├── API/
│   ├── PET-7H24M.ini         # PET-7H24M 設備設定檔
│   ├── csv.ini               # CSV 儲存設定檔
│   └── sql.ini               # SQL 資料庫設定檔
│
├── output/
│   └── PET-7H24M/            # CSV 輸出目錄
│       └── YYYYMMDDHHMMSS_<Label>/
│           ├── YYYYMMDDHHMMSS_<Label>_001.csv
│           ├── YYYYMMDDHHMMSS_<Label>_002.csv
│           └── .sql_temp/    # SQL 暫存檔案目錄（如果啟用 SQL）
│
├── src/
│   ├── pet7h24m.py           # PET-7H24M 核心模組（TCP/IP 通訊）
│   ├── csv_writer.py         # CSV 寫入器模組
│   ├── sql_uploader.py       # SQL 上傳器模組
│   ├── logger.py             # 日誌系統模組
│   ├── main.py               # 主控制程式（Web 介面）
│   ├── requirements.txt      # Python 依賴套件列表
│   ├── include/
│   │   └── hsdaq/
│   │       └── libhsdaq.so   # HSDAQ 函式庫（優先路徑）
│   └── templates/            # HTML 模板目錄
│       ├── index.html         # 主頁模板
│       ├── config.html        # 設定檔管理頁面模板
│       └── files.html         # 檔案瀏覽頁面模板
│
├── docs/
│   └── linux_python3_SDK_Demo/
│       └── python_demo/
│           └── PET-7H24M/
│               └── LinuxArm64/
│                   └── ...    # 官方範例與函式庫備用路徑
│
├── deploy.sh                  # 部署腳本
├── run.sh                     # 啟動腳本
├── README.md                  # 快速開始指南
└── 程式運作說明.md            # 本文件（詳細說明）
```

---

## 程式碼詳細解析

### 關鍵設計決策

#### 1. 降頻處理

**問題**：原始取樣率 20000 Hz，2 通道，每秒產生 40,000 個資料點，前端無法即時處理。

**解決方案**：
- 使用降頻比例 25，每 25 點取 1 點
- 降頻後約 800 Hz，大幅減少前端負擔
- CSV 和 SQL 仍使用原始資料，確保資料完整性

#### 2. 多執行緒架構

**問題**：資料採集、Web 服務、檔案寫入需要同時進行。

**解決方案**：
- 使用 5 個獨立執行緒：Flask、Reading、Collection、CSV Writer、SQL Writer
- 使用 `queue.Queue` 進行執行緒間通訊，避免阻塞
- 使用 `threading.Lock` 保護共享資源

#### 3. 動態通道配置

**問題**：不同應用場景需要不同的通道配置。

**解決方案**：
- 使用位元遮罩（channel_mask）配置通道
- 支援任意通道組合（AI0-AI3）
- 動態計算通道數，自動調整資料處理邏輯

#### 4. 分檔與批次上傳

**問題**：長時間採集會產生超大檔案，不利於處理。

**解決方案**：
- CSV 自動分檔：根據時間間隔（csv.ini 中的 second）自動分檔
- SQL 批次上傳：根據時間間隔（sql.ini 中的 second）批次上傳
- 使用暫存檔案機制，確保資料不遺失

---

## 運作流程

### 啟動流程

1. **執行 `run.sh` 或 `python3 src/main.py`**
2. **載入 HSDAQ 函式庫**
   - 檢查 `src/include/hsdaq/libhsdaq.so`
   - 如果不存在，檢查其他路徑
   - 載入失敗時顯示錯誤並退出
3. **初始化 Flask 應用程式**
   - 設定模板目錄
   - 禁用 Werkzeug 日誌
4. **啟動 Flask 伺服器**（在背景執行緒中）
   - 監聽 `0.0.0.0:8080`
   - 等待 HTTP 請求
5. **主執行緒進入等待迴圈**
   - 等待使用者中斷（Ctrl+C）

### 資料收集流程

1. **使用者點擊「開始讀取」**
   - 前端發送 POST 請求到 `/start`
   - 提供 Label 和可選的 SQL 設定

2. **後端處理啟動請求**
   - 驗證 Label 是否提供
   - 讀取設定檔（PET-7H24M.ini、csv.ini、sql.ini）
   - 初始化 DAQ 設備（`daq_instance.init_devices()`）
   - 動態取得通道數和取樣率
   - 計算 CSV 分檔和 SQL 上傳的目標大小
   - 建立輸出目錄
   - 初始化 CSV Writer
   - 如果啟用 SQL，初始化 SQL Uploader
   - 啟動所有執行緒（Collection、CSV Writer、SQL Writer）
   - 啟動 DAQ 讀取（`daq_instance.start_reading()`）

3. **資料採集開始**
   - Reading Thread 持續讀取設備資料
   - Collection Thread 處理資料並分發到各佇列
   - CSV Writer Thread 持續寫入 CSV 檔案
   - SQL Writer Thread 持續寫入暫存檔案並上傳

4. **前端輪詢資料**
   - 前端每 200ms 發送 GET 請求到 `/data`
   - 後端返回降頻後的增量資料
   - Chart.js 更新圖表

### 停止流程

1. **使用者點擊「停止讀取」**
   - 前端發送 POST 請求到 `/stop`

2. **後端處理停止請求**
   - 設定 `is_collecting = False`
   - 停止 DAQ 讀取（`daq_instance.stop_reading()`）
   - 立即返回成功回應

3. **背景清理工作**
   - 等待所有執行緒完成
   - 上傳 SQL 緩衝區中的剩餘資料
   - 關閉 CSV Writer
   - 關閉 SQL Uploader
   - 清理暫存檔案

---

## 故障排除

### 常見問題

#### 1. 無法連接設備

**症狀**：啟動後無法讀取資料

**解決方法**：
- 檢查 IP 位址是否正確（`PET-7H24M.ini` 中的 `device_ip`）
- 確認設備已正確連接網路
- 檢查防火牆是否允許連接設備的 IP 和埠（9999, 10010）
- 使用 `ping` 確認設備是否可達

#### 2. 找不到 libhsdaq.so

**症狀**：啟動時顯示「無法找到 libhsdaq.so 函式庫」

**解決方法**：
- 確認函式庫檔案已放置在正確路徑（優先：`src/include/hsdaq/libhsdaq.so`）
- 檢查檔案權限（應可讀取）
- 確認函式庫版本與系統架構相容（ARM64 需要 ARM64 版本）

#### 3. 函式庫架構不匹配

**症狀**：啟動時顯示「invalid ELF header」或「wrong ELF class」

**解決方法**：
- **本系統僅支援 LinuxArm64 (aarch64) 架構**
- 確認系統架構（`uname -m` 應顯示 `aarch64`）
- 確認函式庫為 ARM64 版本（使用 `file libhsdaq.so` 檢查）
- 如果顯示 "ELF 64-bit LSB shared object, x86-64"，表示是 x86_64 版本，需要 ARM64 版本
- 從 ICP-DAS 官方取得 ARM64 版本的 libhsdaq.so
- 如果只有 `.a` 檔案，需要重新編譯為 `.so` 檔案

#### 4. Web 介面無法開啟

**症狀**：無法在瀏覽器中開啟網頁

**解決方法**：
- 確認防火牆允許 8080 埠
- 檢查是否有其他程式佔用 8080 埠
- 確認 Python 程式正在執行
- 檢查系統日誌是否有錯誤訊息

#### 5. 資料顯示不正確

**症狀**：圖表顯示異常或資料點不正確

**解決方法**：
- 檢查設定檔中的取樣率和通道數是否正確
- 確認通道數設定與設備匹配
- 檢查瀏覽器控制台是否有 JavaScript 錯誤

#### 6. CSV 檔案未產生

**症狀**：資料收集正常但沒有 CSV 檔案

**解決方法**：
- 檢查 `output/PET-7H24M/` 目錄是否有寫入權限
- 確認 Label 已正確輸入
- 檢查磁碟空間是否充足

#### 7. SQL 上傳失敗

**症狀**：SQL 上傳功能無法正常工作

**解決方法**：
- 檢查 SQL 設定是否正確（`sql.ini`）
- 確認資料庫連線資訊正確
- 檢查資料庫是否允許遠端連線
- 查看系統日誌中的錯誤訊息

---

## 開發說明

### 擴展功能

如需擴展系統功能，可以：

1. **修改前端介面**：編輯 `src/templates/index.html` 和 `src/templates/config.html` 模板
2. **調整圖表設定**：在 `src/templates/index.html` 中修改 Chart.js 的配置選項
3. **新增 API 路由**：在 `src/main.py` 中新增路由處理函數
4. **自訂 CSV 格式**：修改 `src/csv_writer.py` 中的寫入邏輯
5. **新增資料處理**：在 `collection_loop()` 中新增資料處理邏輯

### 程式碼結構

- `pet7h24m.py`：負責 TCP/IP 通訊與資料讀取（使用 HSDAQ 函式庫）
- `csv_writer.py`：負責 CSV 檔案的建立與寫入
- `sql_uploader.py`：負責 MySQL/MariaDB 資料庫上傳
- `logger.py`：統一日誌系統
- `main.py`：整合所有功能，提供 Web 介面（使用 Flask + templates）
- `templates/index.html`：主頁 HTML 模板（包含 Chart.js 圖表）
- `templates/config.html`：設定檔管理頁面模板
- `templates/files.html`：檔案瀏覽頁面模板

---

**最後更新**：2025年12月
**版本**：5.0.0